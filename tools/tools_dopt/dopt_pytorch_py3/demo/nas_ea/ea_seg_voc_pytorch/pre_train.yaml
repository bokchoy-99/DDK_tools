# Network architecture search scenario
scenario:
  strategy:
    name:               NASEA
    framework:          Pytorch
    batch_size: 88 # required, warm-up batch size, must be greater than 0
    epochs: 60 # required, warm-up epochs, must be greater than 0
    supernet:
      input_shape: (3, 224, 224) # optional, currently only supports format is CHW when using pytorch framework
      data_format: "channels_first" # optional, currently only supports "channels_first" when using pytorch framework
      filters: [64, 64, 128, 128, 256, 256, 512, 512] # optional, supports format is [cout,...,cout]
      strides: [1, 1, 2, 1, 2, 1, 1, 1] # optional
    constraint:
      application_type: "image_classification" # required, currently only supports "image_classification" or "semantic_segmentation" when using pytorch framework
      constraint_type: "flops" # required, currently only supports "size" or "flops" when using pytorch framework
      constraint_value: 4357215432 # required, relate to the configuration of "constraint_type", and must be greater than 0.
    optimizer:
      weights_optimizer:
        type: "Adam" # optional, supports "Adam" or "SGD"
        betas: [0.9, 0.999] # optional, two beta, between 0 and 1
        learning_rate: 0.0001 # optional, learning rate, must between 0 and 1
    dataset:
      train_dir: "/some_path/ImageNet/train" # required, path to your training dataset
      val_dir: "/some_path/ImageNet/val" # required, path to your validation dataset
  resource:
    name: pytorch_standalone # required, resource name, support 'tensorflow_standalone' and 'pytorch_standalone'
    gpu_id: 0 # required, configure the gpu id list you want to use
